{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Competition\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_data():\n",
    "    \n",
    "    #get image filenames\n",
    "    cat_locs = glob.glob('catsfolder/*.jpg')\n",
    "    dog_locs = glob.glob('dogsfolder/*.jpg')\n",
    "    num_cats = len(cat_locs)\n",
    "    num_dogs = len(dog_locs)\n",
    "\n",
    "    #initialize empty arrays\n",
    "    X_cats = np.zeros((num_cats,64*64))\n",
    "    X_dogs = np.zeros((num_dogs,64*64))\n",
    "    y_cats = np.zeros((num_cats,1))\n",
    "    y_dogs = np.zeros((num_dogs,1))\n",
    "               \n",
    "    #Load data, reshape into a 1D vector and set labels\n",
    "    \n",
    "    keep_track = 0\n",
    "\n",
    "    for i in range(len(cat_locs)):\n",
    "        img = cat_locs[i]\n",
    "        im = io.imread(img)\n",
    "        im = im.reshape(64*64)\n",
    "        X_cats[i,:] = im\n",
    "        y_cats[i] = -1.0\n",
    "        keep_track += 1\n",
    "\n",
    "    for i in range(len(dog_locs)):\n",
    "        img = dog_locs[i]\n",
    "        im = io.imread(img)\n",
    "        im = im.reshape(64*64)\n",
    "        X_dogs[i,:] = im\n",
    "        y_dogs[i] = 1.0\n",
    "        keep_track += 1\n",
    "    \n",
    "    # combine both datasets\n",
    "    X = np.append(X_cats,X_dogs,0)\n",
    "    y = np.append(y_cats,y_dogs)\n",
    "    \n",
    "    return X, y \n",
    "\n",
    "def split_data(X,y,testpercent):\n",
    "        \n",
    "    [n, d] = X.shape\n",
    "    \n",
    "    ntest = int(round(n*(float(testpercent)/100)))\n",
    "    ntrain = int(round(n - ntest))\n",
    "        \n",
    "    Xtrain = np.zeros((ntrain,d))\n",
    "    Xtest = np.zeros((ntest,d))\n",
    "    ytrain = np.zeros((ntrain,1))\n",
    "    ytest = np.zeros((ntest,1))   \n",
    "        \n",
    "    Data = np.column_stack((X,y))\n",
    "    Data = np.random.permutation(Data)\n",
    "    \n",
    "    for i in range(ntest):\n",
    "        Xtest[i,:] = Data[i,0:d]\n",
    "        ytest[i] = Data[i,d]\n",
    "        \n",
    "    for i in range(ntrain):\n",
    "        Xtrain[i,:] = Data[i+ntest,0:d]\n",
    "        ytrain[i] = Data[i+ntest,d]\n",
    "        \n",
    "    return Xtrain, ytrain, Xtest, ytest\n",
    "\n",
    "def show_image(X, i, label):\n",
    "    #select image\n",
    "    image = X[i,:]\n",
    "    #reshape make into a square\n",
    "    image = image.reshape((64,64))\n",
    "    #display the image\n",
    "    plt.title(label)\n",
    "    plt.imshow(image,'gray')\n",
    "    \n",
    "def calculate_accuracy(ytrue, yguess):\n",
    "    correct = sum(ytrue == yguess)\n",
    "    total = len(ytrue)\n",
    "    accuracy = 100*float(correct)/float(total)\n",
    "    return accuracy\n",
    "\n",
    "X,y = read_data()\n",
    "Xtrain, ytrain, Xtest, ytest = split_data(X, y, 30)\n",
    "\n",
    "class animalsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y): \n",
    "        X_ = torch.tensor(X)\n",
    "        self.X = torch.zeros(len(X), 1, 64, 64, dtype=torch.float)\n",
    "        self.y = torch.tensor(y, dtype=torch.int64)\n",
    "        for k, i in enumerate(X_):\n",
    "            new_i = i[np.newaxis, np.newaxis, :]\n",
    "            new_i.resize_(1, 64, 64)\n",
    "            self.X[k] = new_i\n",
    "        self.X = self.X / 1000\n",
    "        for k, i in enumerate(self.y):\n",
    "            if i == -1:\n",
    "                self.y[k] = 0\n",
    "            elif i == 1:\n",
    "                self.y[k] = 1\n",
    "        self.y = self.y.clone().detach().squeeze()\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = tuple((self.X[index], self.y[index]))\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainData = animalsDataset(Xtrain, ytrain)\n",
    "testData = animalsDataset(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, Layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            self.hidden.append(nn.Linear(input_size, output_size))\n",
    "    \n",
    "    def forward(self, activation):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "            if l < L - 1:\n",
    "                activation = F.relu(linear_transform(activation))\n",
    "            else:\n",
    "                activation = linear_transform(activation)\n",
    "                activation = F.softmax(activation, dim = 1)\n",
    "        return activation\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, out_1=16, out_2=32):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn0 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size = 4, stride=1, padding=1)\n",
    "        self.conv0_bn = nn.BatchNorm2d(8)\n",
    "        self.relu0 = nn.ReLU()\n",
    "        self.maxpool0 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn1 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(1568, 2)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        out = self.cnn0(x)\n",
    "        out = self.conv0_bn(out)\n",
    "        out = self.relu0(out)\n",
    "        out = self.maxpool0(out)\n",
    "        out = self.cnn1(out)\n",
    "        out = self.conv1_bn(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.conv2_bn(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.softmax(out, dim = 1)\n",
    "        return out\n",
    "    \n",
    "'''\n",
    "model=nn.Sequential(\n",
    "    nn.Linear(4096, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 2),\n",
    "    nn.Softmax(dim = 1))\n",
    "'''\n",
    "\n",
    "\n",
    "#model = Net([4096, 1000, 1000, 100, 2])\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainData, batch_size=10)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=testData, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "N_train = len(trainData)\n",
    "N_validate = len(testData)\n",
    "\n",
    "def train_model(n_epochs):\n",
    "    for i, epoch in enumerate(range(n_epochs)):\n",
    "        print(\"Epoch \" + str(i + 1))\n",
    "        correct = 0\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x) #z = model(x.view(-1, 64 * 64))\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y).sum().item()\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        accuracy = correct / N_train\n",
    "        print(\"Training accuracy: \", accuracy * 100, \"%\")\n",
    "\n",
    "        \n",
    "        correct=0  \n",
    "        for x_test, y_test in validation_loader:\n",
    "            z = model(x_test) #z = model(x_test.view(-1, 64 * 64))\n",
    "            _, yhat = torch.max(z.data, 1)\n",
    "            correct += (yhat == y_test).sum().item()\n",
    "        accuracy = correct / N_validate\n",
    "        accuracy_list.append(accuracy)\n",
    "        loss_list.append(loss.data)\n",
    "        print(\"Validation accuracy: \", round(accuracy * 100, 2), \"%\")\n",
    "        print()\n",
    "        \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training accuracy:  88.42857142857142 %\n",
      "Validation accuracy:  92.0 %\n",
      "\n",
      "Epoch 2\n",
      "Training accuracy:  95.28571428571428 %\n",
      "Validation accuracy:  94.83 %\n",
      "\n",
      "Epoch 3\n",
      "Training accuracy:  96.71428571428572 %\n",
      "Validation accuracy:  96.17 %\n",
      "\n",
      "Epoch 4\n",
      "Training accuracy:  97.64285714285714 %\n",
      "Validation accuracy:  96.0 %\n",
      "\n",
      "Epoch 5\n",
      "Training accuracy:  98.07142857142857 %\n",
      "Validation accuracy:  96.67 %\n",
      "\n",
      "Epoch 6\n",
      "Training accuracy:  98.14285714285714 %\n",
      "Validation accuracy:  97.5 %\n",
      "\n",
      "Epoch 7\n",
      "Training accuracy:  98.57142857142858 %\n",
      "Validation accuracy:  97.83 %\n",
      "\n",
      "Epoch 8\n",
      "Training accuracy:  99.0 %\n",
      "Validation accuracy:  98.0 %\n",
      "\n",
      "Epoch 9\n",
      "Training accuracy:  99.07142857142858 %\n",
      "Validation accuracy:  97.83 %\n",
      "\n",
      "Epoch 10\n",
      "Training accuracy:  99.14285714285714 %\n",
      "Validation accuracy:  97.83 %\n",
      "\n",
      "Final accuracy:  97.83 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(n_epochs)\n",
    "print(\"Final accuracy: \", round(accuracy * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  98.75 %\n"
     ]
    }
   ],
   "source": [
    "#To run test on pre-trained model, run what is below. The only modification that must be made is changing the\n",
    "#directories in read_data (or simply name the test directories as outlined in read_data()) so that X, y correspond \n",
    "#to the correct test data.\n",
    "\n",
    "plt.close(\"all\")\n",
    "X, y = read_data()\n",
    "Xtrain, ytrain, Xtest, ytest = split_data(X, y, 100)\n",
    "testDataset = animalsDataset(Xtest, ytest)\n",
    "final_loader = torch.utils.data.DataLoader(dataset=testDataset, batch_size=1)\n",
    "yguess = np.zeros(len(ytest))\n",
    "shown = 0\n",
    "for i, (observation, label) in enumerate(final_loader):\n",
    "    z = model(observation)\n",
    "    _, yhat = torch.max(z.data, 1)\n",
    "    yhat = yhat.item()\n",
    "    if yhat == 0:\n",
    "        guess = -1\n",
    "        yguess[i] = guess\n",
    "    elif yhat == 1:\n",
    "        guess = 1\n",
    "        yguess[i] = guess\n",
    "    if(shown < 19 and guess != ytest[i]):\n",
    "        label = \"Cat: \" + str(round(z[0][0].item() * 100)) + \"% Dog: \" + str(round(z[0][1].item() * 100)) + \"%\" \n",
    "        show_image(Xtest, i, label = label)\n",
    "        plt.figure()\n",
    "        shown += 1\n",
    "\n",
    "ytest = np.reshape(ytest, 2000)\n",
    "\n",
    "print(\"Accuracy: \", calculate_accuracy(ytest, yguess), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
